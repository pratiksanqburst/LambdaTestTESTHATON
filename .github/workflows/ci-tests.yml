name: CI - API divergence + generated tests (no inline Python)

on:
  workflow_dispatch: {}
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  contents: read

jobs:
  generate-and-run:
    runs-on: ubuntu-latest
    env:
      SOURCE_DIR: backend
      OUTPUT_DIR: output

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Add workspace to PYTHONPATH
        run: echo "PYTHONPATH=${GITHUB_WORKSPACE}" >> $GITHUB_ENV

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Set up Node 20
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python requirements
        run: |
          python3 -m pip install --upgrade pip
          if [ -f requirements.txt ]; then python3 -m pip install -r requirements.txt; fi
          python3 -m pip install pyyaml openai || true
        shell: bash

      - name: Install Newman
        run: npm install newman newman-reporter-html
        shell: bash

      - name: Debug routes
        run: |
          if [ -f scripts/debug_routes.py ]; then
            python3 -u scripts/debug_routes.py || true
          else
            echo "debug_routes.py missing"
          fi
        shell: bash

      - name: Run CI runner (generate collection)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          API_KEY: ${{ secrets.OPENAI_API_KEY }}
          QBURST_GATEWAY: ${{ secrets.QBURST_GATEWAY }}
        run: |
          mkdir -p "${OUTPUT_DIR}"
          python3 -u ci_runner.py \
            --source-dir "${SOURCE_DIR}" \
            --use-llm \
            --gateway-url "${QBURST_GATEWAY}" \
            --output-dir "${OUTPUT_DIR}"
        shell: bash

      - name: Show generated output files
        run: |
          ls -la "${OUTPUT_DIR}" || true
          if [ -f "${OUTPUT_DIR}/postman_collection.json" ]; then
            head -n 120 "${OUTPUT_DIR}/postman_collection.json"
          fi
        shell: bash

      #########################################################################
      # HYPEREXECUTE DIRECT UPLOAD (NO PYTHON INLINE)
      #########################################################################

      - name: Run collection on HyperExecute
        env:
          LT_USERNAME: ${{ secrets.LT_USERNAME }}
          LT_ACCESS_KEY: ${{ secrets.LT_ACCESS_KEY }}
          HYPEREXECUTE_PROJECT: ${{ secrets.HYPEREXECUTE_PROJECT }}
          BASE_URL: ${{ secrets.BASE_URL }}
        run: |
          set -euo pipefail

          COLLECTION="${OUTPUT_DIR}/postman_collection.json"
          if [ ! -f "$COLLECTION" ]; then
            echo "postman_collection.json not found"
            exit 0
          fi

          # Create base64 string (safe for JSON)
          COLLECTION_B64=$(base64 -w 0 "$COLLECTION")

          # Install jq if missing
          sudo apt-get update -y >/dev/null 2>&1
          sudo apt-get install -y jq >/dev/null 2>&1

          # Trigger HyperExecute
          TRIGGER_RESPONSE=$(curl -s -u "${LT_USERNAME}:${LT_ACCESS_KEY}" \
            -H "Content-Type: application/json" \
            -X POST "https://hyperexecute.lambdatest.com/api/v1/runs" \
            -d "$(jq -n \
              --arg project "${HYPEREXECUTE_PROJECT}" \
              --arg collection "${COLLECTION_B64}" \
              --arg base "${BASE_URL}" \
              '{project:$project, collection_base64:$collection, env:{base_url:$base}, concurrency:3}'
            )")

          echo "$TRIGGER_RESPONSE" > hyperexecute-trigger.json
          cat hyperexecute-trigger.json | jq .

          RUN_ID=$(cat hyperexecute-trigger.json | jq -r '.runId // .id // ""')
          DASHBOARD_URL=$(cat hyperexecute-trigger.json | jq -r '.dashboardUrl // .reportUrl // ""')

          echo "RUN_ID=$RUN_ID"
          echo "DASHBOARD_URL=$DASHBOARD_URL"

          # If no run ID, stop
          if [ -z "$RUN_ID" ]; then
            echo "No RUN_ID returned. Cannot poll."
            echo "DASHBOARD_URL=${DASHBOARD_URL}" > hyperexecute-metadata.env
            echo "RUN_ID=" >> hyperexecute-metadata.env
            exit 0
          fi

          # Poll run status
          MAX_TRIES=60
          SLEEP_SECONDS=20

          for i in $(seq 1 $MAX_TRIES); do
            STATUS_JSON=$(curl -s -u "${LT_USERNAME}:${LT_ACCESS_KEY}" \
              "https://hyperexecute.lambdatest.com/api/v1/runs/${RUN_ID}/status")

            STATUS=$(echo "$STATUS_JSON" | jq -r '.status // ""')

            echo "Attempt $i - Status = $STATUS"

            if [ "$STATUS" = "COMPLETED" ] || [ "$STATUS" = "FINISHED" ] || [ "$STATUS" = "SUCCESS" ]; then
              break
            fi

            if [ "$STATUS" = "FAILED" ] || [ "$STATUS" = "ERROR" ]; then
              break
            fi

            sleep $SLEEP_SECONDS
          done

          # Download report
          curl -s -u "${LT_USERNAME}:${LT_ACCESS_KEY}" \
            -o hyperexecute-report.zip \
            "https://hyperexecute.lambdatest.com/api/v1/runs/${RUN_ID}/report" || true

          echo "DASHBOARD_URL=${DASHBOARD_URL}" > hyperexecute-metadata.env
          echo "RUN_ID=${RUN_ID}" >> hyperexecute-metadata.env
        shell: bash


      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: api-test-artifacts
          path: |
            output/postman_collection.json
            output/divergence_report.json
            output/llm_error.log
            hyperexecute-trigger.json
            hyperexecute-metadata.env
            hyperexecute-report.zip

      - name: Comment PR with dashboard link
        if: ${{ github.event_name == 'pull_request' }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if [ -f hyperexecute-trigger.json ]; then
            DASHBOARD_URL=$(jq -r '.dashboardUrl // .reportUrl // ""' hyperexecute-trigger.json)
            RUN_ID=$(jq -r '.runId // .id // ""' hyperexecute-trigger.json)
          fi

          if [ -z "$DASHBOARD_URL" ] && [ -n "$RUN_ID" ]; then
            DASHBOARD_URL="https://hyperexecute.lambdatest.com/runs/${RUN_ID}"
          fi

          if [ -n "$DASHBOARD_URL" ]; then
            PR=${{ github.event.pull_request.number }}
            COMMENT="HyperExecute Test Run Completed. Dashboard: ${DASHBOARD_URL}"
            jq -n --arg body "$COMMENT" '{body:$body}' |
              curl -s -X POST \
                -H "Authorization: token ${GH_TOKEN}" \
                -H "Content-Type: application/json" \
                "https://api.github.com/repos/${{ github.repository }}/issues/${PR}/comments" \
                -d @-
          else
            echo "No dashboard URL to post."
          fi
        shell: bash
